/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.automq.stream.s3;

import com.automq.stream.s3.metadata.ObjectUtils;
import com.automq.stream.s3.metadata.S3ObjectMetadata;
import com.automq.stream.s3.metadata.S3ObjectType;
import com.automq.stream.s3.network.ThrottleStrategy;
import com.automq.stream.s3.operator.S3Operator;
import com.automq.stream.s3.operator.Writer;
import io.netty.buffer.ByteBuf;
import io.netty.buffer.CompositeByteBuf;
import java.util.LinkedList;
import java.util.List;
import java.util.concurrent.CompletableFuture;

public class StreamObjectCopier {
    private final List<StreamObjectIndexData> completedObjects;
    private final S3Operator s3Operator;
    private final Writer writer;
    private long nextObjectDataStartPosition;
    private int blockCount;
    /**
     * The number of copy-write operations for a small object(range). It can indicate the frequency of reading in copy-write.
     */
    private int smallSizeCopyWriteCount;

    private long size;

    public StreamObjectCopier(long objectId, S3Operator s3Operator) {
        this.s3Operator = s3Operator;
        // TODO: use a better clusterName
        this.writer = s3Operator.writer(ObjectUtils.genKey(0, objectId), ThrottleStrategy.THROTTLE_2);
        this.completedObjects = new LinkedList<>();
        this.nextObjectDataStartPosition = 0;
        this.blockCount = 0;
        this.size = 0;
        this.smallSizeCopyWriteCount = 0;
    }

    public void copy(S3ObjectMetadata metadata) {
        splitAndCopy(metadata, 1);
    }

    public void splitAndCopy(S3ObjectMetadata metadata, int splitCount) {
        if (metadata.getType() != S3ObjectType.STREAM) {
            throw new IllegalArgumentException("Only stream object can be handled.");
        }
        if (metadata.objectSize() <= 0) {
            throw new IllegalArgumentException("Object size must be positive.");
        }
        if (splitCount <= 0) {
            throw new IllegalArgumentException("Split count must be positive.");
        }
        try (ObjectReader reader = new ObjectReader(metadata, s3Operator)) {
            ObjectReader.BasicObjectInfo basicObjectInfo = reader.basicObjectInfo().join();

            long remainingBytes = basicObjectInfo.dataBlockSize();
            // Only copy data blocks for now.
            for (long i = 0; i < splitCount - 1 && remainingBytes >= Writer.MAX_PART_SIZE; i++) {
                copyWrite(metadata.key(), i * Writer.MAX_PART_SIZE, (i + 1) * Writer.MAX_PART_SIZE);
                remainingBytes -= Writer.MAX_PART_SIZE;
            }
            if (remainingBytes > Writer.MAX_PART_SIZE) {
                throw new IllegalArgumentException("splitCount is too small, remaining bytes: " + remainingBytes + " is larger than MAX_PART_SIZE: " + Writer.MAX_PART_SIZE + ".");
            }
            if (remainingBytes > 0) {
                copyWrite(metadata.key(), (splitCount - 1) * Writer.MAX_PART_SIZE, basicObjectInfo.dataBlockSize());
            }

            completedObjects.add(new StreamObjectIndexData(basicObjectInfo.indexBlock(), nextObjectDataStartPosition, blockCount));
            blockCount += basicObjectInfo.blockCount();
            nextObjectDataStartPosition += basicObjectInfo.dataBlockSize();
            size += basicObjectInfo.dataBlockSize();
        }
    }

    private void copyWrite(String key, long start, long end) {
        if (end - start <= Writer.MIN_PART_SIZE) {
            smallSizeCopyWriteCount++;
        }
        writer.copyWrite(key, start, end);
    }

    public CompletableFuture<Void> close() {
        CompositeByteBuf buf = DirectByteBufAlloc.compositeByteBuffer();
        IndexBlock indexBlock = new IndexBlock();
        buf.addComponent(true, indexBlock.buffer());
        ObjectWriter.Footer footer = new ObjectWriter.Footer(indexBlock.position(), indexBlock.size());
        buf.addComponent(true, footer.buffer());
        writer.write(buf.duplicate());
        size += indexBlock.size() + footer.size();
        return writer.close();
    }

    public int smallSizeCopyWriteCount() {
        return smallSizeCopyWriteCount;
    }

    public long size() {
        return size;
    }

    static class StreamObjectIndexData {
        private final ByteBuf blockBuf;
        private final ByteBuf rangesBuf;

        public StreamObjectIndexData(ObjectReader.IndexBlock indexBlock, long blockStartPosition, int blockStartId) {
            this.blockBuf = indexBlock.blocks().copy();
            this.rangesBuf = indexBlock.streamRanges().copy();

            int blockPositionIndex = 0;
            while (blockPositionIndex < blockBuf.readableBytes()) {
                // The value is now the relative block position.
                long blockPosition = blockBuf.getLong(blockPositionIndex);
                // update block position with start position.
                blockBuf.setLong(blockPositionIndex, blockPosition + blockStartPosition);
                blockPositionIndex += 8 + 4 + 4;
            }

            int startBlockIdIndex = 8 + 8 + 4;
            while (startBlockIdIndex < rangesBuf.readableBytes()) {
                // The value is now the relative block id.
                int blockId = rangesBuf.getInt(startBlockIdIndex);
                // update block id with start block id.
                rangesBuf.setInt(startBlockIdIndex, blockId + blockStartId);
                startBlockIdIndex += 8 + 8 + 4 + 4;
            }
        }

        public ByteBuf blockBuf() {
            return blockBuf.duplicate();
        }

        public ByteBuf rangesBuf() {
            return rangesBuf.duplicate();
        }
    }

    private class IndexBlock {
        private final CompositeByteBuf buf;
        private final long position;

        public IndexBlock() {
            position = nextObjectDataStartPosition;
            buf = DirectByteBufAlloc.compositeByteBuffer();
            // block count
            buf.addComponent(true, DirectByteBufAlloc.byteBuffer(4).writeInt(blockCount));
            // block index
            for (StreamObjectIndexData indexData : completedObjects) {
                buf.addComponent(true, indexData.blockBuf());
            }
            // object stream range
            for (StreamObjectIndexData indexData : completedObjects) {
                buf.addComponent(true, indexData.rangesBuf());
            }
        }

        public ByteBuf buffer() {
            return buf.duplicate();
        }

        public long position() {
            return position;
        }

        public int size() {
            return buf.readableBytes();
        }
    }
}
